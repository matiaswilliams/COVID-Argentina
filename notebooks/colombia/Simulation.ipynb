{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation notebook - Colombia data\n",
    "\n",
    "This notebook generates a people dataframe with 500k+ people from the manzanas data, and runs the HMM-based simualtion with fixed transitions over them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
    {
     "name": "stdout",
   "outputs": [],
   "source": [
    "## General Imports\n",
    "import sys\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from IPython.display import display\n",
    "from timeit import default_timer as timer\n",
    "import swifter\n",
    "from tqdm.notebook import tqdm\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "from shapely.ops import nearest_points\n",
    "from shapely import wkt\n",
    "from copy import deepcopy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Project Imports\n",
    "sys.path.append(\"../..\")\n",
    "import model \n",
    "from model.sim import location, state, contacts\n",
    "from colombia_utils import *\n",
    "\n",
    "\n",
    "NUM_STATES = 9\n",
    "\n",
    "## Constants\n",
    "shp_path = '../../../shp' # Change to your local shape file directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print info on manzana data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of people in mnz: 89.66901408450704\n",
      "Number of manzanas: 5964\n",
      "Total number of people: 534786\n"
     ]
    }
   ],
   "source": [
    "mnz_data = gpd.read_file(os.path.join(shp_path,\"Censo_personas_manzanas_2018.shp\"))\n",
    "mnz_data = mnz_data.to_crs({\"init\": \"EPSG:3857\"})\n",
    "print(\"Average number of people in mnz:\", mnz_data['SEXO_TOTAL'].mean())\n",
    "print(\"Number of manzanas:\", len(mnz_data))\n",
    "print(\"Total number of people:\", mnz_data['SEXO_TOTAL'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate daily contacts\n",
    "Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_daily_contacts(people_proj, sim, load_from_csv=True):\n",
    "    \n",
    "    if load_from_csv:\n",
    "        return pd.read_csv(\"improved_daily_contacts.csv\")\n",
    "    \n",
    "    start = timer()\n",
    "\n",
    "    # calculate daily contacts for day 1 as they will be repeated for the other days\n",
    "    date = sim[\"dates\"][\"date\"][0]\n",
    "    daily_contacts = people_proj.apply(calculate_contacts, axis=1, args=[people_proj, date])\n",
    "\n",
    "    original_daily_contacts = pd.concat(list(daily_contacts), sort=False)\n",
    "    original_daily_contacts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # calculate the table for all the dates\n",
    "    improved_daily_contacts = original_daily_contacts.copy()\n",
    "    for date in sim[\"dates\"][\"date\"]:\n",
    "        if len(original_daily_contacts[original_daily_contacts['date'] == date]) < 1:\n",
    "            new_df = original_daily_contacts.copy()\n",
    "            new_df['date'] = date\n",
    "            improved_daily_contacts = improved_daily_contacts.append(new_df)\n",
    "\n",
    "    improved_daily_contacts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    end = timer()\n",
    "    print(\"Compute time:\",end-start)\n",
    "    \n",
    "    return improved_daily_contacts\n",
    "\n",
    "# improved_daily_contacts = calculate_daily_contacts(people_proj, sim)\n",
    "# sim[\"contacts\"] = improved_daily_contacts\n",
    "# sim[\"N_c\"] = contacts.calculate_Nc(sim)\n",
    "# print(\"Average daily contacts: {}\".format(sim[\"N_c\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(improved_daily_contacts[\"date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save=False\n",
    "# if save:   \n",
    "#     improved_daily_contacts.to_csv(\"improved_daily_contacts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gpd.GeoDataFrame(\n",
    "#     df,\n",
    "#     geometry=gpd.points_from_xy(\n",
    "#         df[\"longitude\"],\n",
    "#         df[\"latitude\"],\n",
    "#     ),\n",
    "#     crs={\"init\":\"EPSG:4326\"},\n",
    "# )\n",
    "\n",
    "# # 10 records\n",
    "# filtered_df\n",
    "\n",
    "# filtered_gdf = gpd.GeoDataFrame(\n",
    "#     filtered_df, \n",
    "#     geometry=gpd.points_from_xy(\n",
    "#         filtered_df[\"longitude\"],\n",
    "#         filtered_df[\"latitude\"],\n",
    "#     ),\n",
    "#     crs={\"init\":\"EPSG:4326\"},\n",
    "# )\n",
    "\n",
    "# # EPSG:3857 converts it to meters, correct?\n",
    "\n",
    "# gdf_proj = gdf.to_crs({\"init\": \"EPSG:3857\"})\n",
    "# filtered_gdf_proj = filtered_gdf.to_crs({\"init\": \"EPSG:3857\"})\n",
    "\n",
    "# # so 100 miles would be 160934 meters\n",
    "\n",
    "# x = filtered_gdf_proj.buffer(100).unary_union\n",
    "\n",
    "# neighbours = gdf_proj[\"geometry\"].intersection(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create people dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prateekmittal/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98a79e4727f473fa7a924445838d16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final shape of people_df: (534786, 3)\n",
      "    patient   age                                      position\n",
      "0         0   2.0  POINT (-8322741.621359553 1221795.910856193)\n",
      "1         1  12.0  POINT (-8322741.621359553 1221795.910856193)\n",
      "2         2  17.0  POINT (-8322741.621359553 1221795.910856193)\n",
      "3         3  17.0  POINT (-8322741.621359553 1221795.910856193)\n",
      "4         4  17.0  POINT (-8322741.621359553 1221795.910856193)\n",
      "..      ...   ...                                           ...\n",
      "95       95  42.0  POINT (-8322966.020286302 1221875.367794984)\n",
      "96       96  42.0  POINT (-8322966.020286302 1221875.367794984)\n",
      "97       97  42.0  POINT (-8322966.020286302 1221875.367794984)\n",
      "98       98  42.0  POINT (-8322966.020286302 1221875.367794984)\n",
      "99       99  42.0  POINT (-8322966.020286302 1221875.367794984)\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Build people_full dataframe containing census data, infected data + estimated people from neighborhood data\n",
    "\n",
    "def create_people_df_from_mnz_data(mnz_data, create_contacts=True):\n",
    "\n",
    "#     people_df = pd.DataFrame()\n",
    "    contacts_df_list = []\n",
    "    i = 0\n",
    "    first_pass = True\n",
    "    for idx, row in tqdm(mnz_data.iterrows()):\n",
    "        n_ppl_in_mnz = row[\"SEXO_TOTAL\"]\n",
    "        if not n_ppl_in_mnz:\n",
    "            continue\n",
    "        \n",
    "#         print(\"row.geometry.centroid\",row.geometry.centroid)\n",
    "#         dummy_row.geometry = row.geometry\n",
    "#       person_row = pd.DataFrame({\"patient\": [0], \"position\": [row.geometry.centroid]})\n",
    "        person_row = pd.DataFrame({\"patient\": [0], \"age\": [0], \"position\": [row.geometry.centroid]})\n",
    "        \n",
    "#         dummy_row[\"calculated_centroid\"] = row.geometry.centroid\n",
    "#         print(dummy_row.columns)\n",
    "        ppl_in_mnz = pd.concat([person_row]*n_ppl_in_mnz)\n",
    "        ids = np.arange(i, i+n_ppl_in_mnz)\n",
    "        ages = np.concatenate((np.array([2]*row[\"EDAD_0_4\"]),\n",
    "                               np.array([7]*row[\"EDAD_5_9\"]),\n",
    "                               np.array([12]*row[\"EDAD_10_14\"]),\n",
    "                               np.array([17]*row[\"EDAD_15_19\"]),\n",
    "                               np.array([22]*row[\"EDAD_20_24\"]),\n",
    "                               np.array([27]*row[\"EDAD_25_29\"]),\n",
    "                               np.array([32]*row[\"EDAD_30_34\"]),\n",
    "                               np.array([37]*row[\"EDAD_35_39\"]),\n",
    "                               np.array([42]*row[\"EDAD_40_44\"]),\n",
    "                               np.array([47]*row[\"EDAD_45_49\"]),\n",
    "                               np.array([52]*row[\"EDAD_50_54\"]),\n",
    "                               np.array([57]*row[\"EDAD_55_59\"]),\n",
    "                               np.array([62]*row[\"EDAD_60_64\"]),\n",
    "                               np.array([67]*row[\"EDAD_65_69\"]),\n",
    "                               np.array([72]*row[\"EDAD_70_74\"]),\n",
    "                               np.array([77]*row[\"EDAD_75_79\"]),\n",
    "                               np.array([82]*row[\"EDAD_80_84\"]),\n",
    "                               np.array([87]*row[\"EDAD_85_89\"]),\n",
    "                               np.array([92]*row[\"EDAD_90_94\"]),\n",
    "                               np.array([97]*row[\"EDAD_95_99\"]),\n",
    "                               np.array([100]*row[\"EDAD_100_O\"])\n",
    "                               ))\n",
    "        ppl_in_mnz.patient = ids\n",
    "        ppl_in_mnz.age = ages\n",
    "        i+=n_ppl_in_mnz\n",
    "        if first_pass:\n",
    "            people_df = ppl_in_mnz\n",
    "            first_pass = False\n",
    "        else:\n",
    "            people_df = people_df.append(ppl_in_mnz, ignore_index=True)\n",
    "            \n",
    "        \n",
    "        if create_contacts:\n",
    "            for date in range(90):\n",
    "                for id_ in ids:\n",
    "                    data = {\n",
    "                            'date': np.repeat(date, n_ppl_in_mnz),\n",
    "                            'patient1': np.repeat(id_, n_ppl_in_mnz),\n",
    "                            'patient2': ids\n",
    "                        }\n",
    "                    patient_contact = pd.DataFrame(data=data, columns = [\"date\", \"patient1\", \"patient2\"])\n",
    "                    csv_name = \"contacts/contacts_patient%d_date%d.csv\" % (id_, date)\n",
    "                    if not os.path.exists(csv_name):\n",
    "                        patient_contact.to_csv(csv_name)\n",
    "#                     contacts_df_list.append(pd.DataFrame(data=data, columns = [\"date\", \"patient1\", \"patient2\"]))    \n",
    "    print(\"Final shape of people_df:\",people_df.shape)\n",
    "    if create_contacts:\n",
    "        contacts_df = pd.concat(contacts_df_list, sort=False)\n",
    "        contacts_df.reset_index(drop=True, inplace=True)\n",
    "        return people_df, contacts_df\n",
    "    else:\n",
    "        return people_df, None\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "large_people_df, large_contacts_df = create_people_df_from_mnz_data(mnz_data, \n",
    "                                                                    create_contacts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people before adding infected: 534786\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of people before adding infected:\",len(large_people_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded people df with shape: (534786, 3)\n",
      "Columns in people df: Index(['patient', 'age', 'position'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "load_people_df=False\n",
    "if load_people_df:\n",
    "    large_people_df = pd.read_csv(\"people_df_from_manzanas.csv\")\n",
    "    \n",
    "print(\"Loaded people df with shape:\", large_people_df.shape)\n",
    "print(\"Columns in people df:\", large_people_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_people_df=False\n",
    "if save_people_df:\n",
    "    large_people_df.to_csv(\"people_df_from_manzanas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Shape of contacts df (should be people_df*90*avg_n_contacts)\", contacts_df.shape)\n",
    "# contacts_df.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolate contacts (DEPRECATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def nearest(row, geom_union, df1, df2, geom1_col='geometry', geom2_col='geometry', src_column=None):\n",
    "#     \"\"\"Find the nearest point and return the corresponding value from specified column.\"\"\"\n",
    "#     # Find the geometry that is closest\n",
    "#     nearest = df2[geom2_col] == nearest_points(row[geom1_col], geom_union)[1]\n",
    "#     # Get the corresponding value from df2 (matching is based on the geometry)\n",
    "#     value = df2[nearest][src_column].get_values()[0]\n",
    "#     return value\n",
    "\n",
    "# def nearest(point, people_df):\n",
    "#     people_locs = people_df.geometry.centroid.unary_union\n",
    "    \n",
    "# #     print(\"Trying to find nearest point to %s\" % point)\n",
    "# #     print(\"Candidates are:\", people_locs[:5], \"and more (%d total)\" % len(people_locs)) # \"with ids:\", people_df[\"patient\"][:5]\n",
    "    \n",
    "#     # find the nearest person for which we have data\n",
    "# #     print(\"people_df.geometry.centroid\", people_df.geometry.centroid)\n",
    "# #     print(\"nearest_points(point, people_locs)\", nearest_points(point, people_locs))\n",
    "#     nearest = people_df.geometry.centroid == nearest_points(point, people_locs)[1]\n",
    "# #     print(nearest)\n",
    "    \n",
    "#     return people_df[nearest]\n",
    "\n",
    "# def calculate_contacts(polygon, points, date):\n",
    "#     _people = points[points.geometry.centroid.within(polygon.geometry.buffer(100))]\n",
    "#     data = {\n",
    "#         'date': np.repeat(date, len(_people)),\n",
    "#         'patient1': np.repeat(polygon['patient'], len(_people)),\n",
    "#         'patient2': list(_people['patient'])\n",
    "#     }\n",
    "    \n",
    "#     exposure_df = pd.DataFrame(data=data, columns = [\"date\", \"patient1\", \"patient2\"])\n",
    "#     return exposure_df\n",
    "\n",
    "# def contacts_from_closest_person(row, people, contacts):\n",
    "#     print(\"\\nGetting contacts for person\", row[\"patient\"])\n",
    "#     nearest_person = nearest(row.calculated_centroid, people)\n",
    "#     contact_df = contacts[contacts['patient1']==nearest_person[\"patient\"].iloc[0]]\n",
    "#     contact_df.patient1 = row[\"patient\"]\n",
    "# #     print(contact_df)\n",
    "#     print(\"Found nearest person. ID: %s. Centroid: %s. Barrio: %s. Contacts: %d\" % (nearest_person[\"patient\"], nearest_person.geometry.centroid,\n",
    "#                                                                                    nearest_person.BARRIO, len(contact_df))) \n",
    "    \n",
    "#     return contact_df\n",
    "\n",
    "# def contacts_from_neigh(row, people, contacts):\n",
    "    \n",
    "#     contacts_for_this_id = neigh2contacts[row[\"\"]]\n",
    "#     return contacts\n",
    "\n",
    "# def dummy_contacts(row, people, contacts):\n",
    "#     contact_df = contacts.iloc[:30]\n",
    "#     contact_df.patient1 = row[\"patient\"]\n",
    "#     data = {\n",
    "#         'date': contact_df[\"date\"].to_numpy(),\n",
    "#         'patient1': contact_df[\"patient1\"].to_numpy(),\n",
    "#         'patient2':  contact_df[\"patient2\"].to_numpy()\n",
    "#     }\n",
    "#     contact_df = pd.DataFrame(data=data, columns = [\"date\", \"patient1\", \"patient2\"])\n",
    "#     return contact_df\n",
    "    \n",
    "# def extrapolate_contacts(contacts, people, full_people):\n",
    "#     print(\"Extrapolating contacts for full dataframe of length %d from small dataframe of length %d\" % (len(full_people), len(people)))\n",
    "# #     extrapolated_contacts = full_people.apply(contacts_from_closest_person, axis=1, args=[people, contacts])\n",
    "#     ddata = dd.from_pandas(full_people, npartitions=100)\n",
    "#     extrapolated_contacts = ddata.map_partitions(lambda df: df.apply(calculate_contacts, axis=1, args=[people, date])).compute(get=get) \n",
    "#     return extrapolated_contacts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(improved_daily_contacts.columns)\n",
    "# extrapolated_contacts = extrapolate_contacts(improved_daily_contacts, people_proj, large_people_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"shape extrapolated contacts:\", extrapolated_contacts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save=True\n",
    "# if save:\n",
    "#     extrapolated_contacts.to_csv(\"extrapolated_contacts.csv\")\n",
    "    \n",
    "# load=False\n",
    "# if load:\n",
    "#     extrapolated_contacts = pd.read_csv(\"extrapolated_contacts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mnz2id dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053adaca48134167aa357e40d88da445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9748e2d68c5b4941a69eda0d4fe3f694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5964.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mnz2ids = get_mnz2ids(mnz_data)\n",
    "id2mnz = get_id2mnz(mnz2ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of infected\n",
    "\n",
    "Some of the infected have an address that is in none of the manzanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def include_infected_to_people_df(people_df, \n",
    "                                 mnz2ids, \n",
    "                                 id2mnz,\n",
    "                                 path_to_infected_file=os.path.join(shp_path,\"POSITIVOS_COVID_19.shp\"), \n",
    "                                 T=90):\n",
    "    mnz2ids_inf = deepcopy(mnz2ids)\n",
    "    id2mnz_inf = deepcopy(id2mnz)\n",
    "    \n",
    "    infected = gpd.read_file(path_to_infected_file)\n",
    "    \n",
    "    print(infected.shape)\n",
    "    print(infected.columns)\n",
    "    \n",
    "    if \"estado_ate\" in infected.columns:\n",
    "        inf_active = infected[infected[\"estado_ate\"]==1]\n",
    "    else:\n",
    "        inf_active = infected\n",
    "\n",
    "    print(\"Loaded %d infected rows\" % len(inf_active))\n",
    "    print(\"people_df.shape before infected concat\", people_df.shape)\n",
    "    max_id = people_df.patient.max()\n",
    "    assert(max_id == max(id2mnz_inf.keys()))\n",
    "    infected_ids = np.arange(len(inf_active))+max_id+1\n",
    "\n",
    "    infected_of_interest = []\n",
    "    \n",
    "    # Find mnz corresponding to each infected\n",
    "    c=0\n",
    "    for i, mnz in tqdm(mnz_data.iterrows()):\n",
    "#         print(\"\\nsearching if any infected in mnz %d\" % i)\n",
    "        infected_ids_in_mnz = infected_ids[inf_active.geometry.centroid.within(mnz.geometry.buffer(100))]\n",
    "#         print(\"found %d infected in mnz\" % len(infected_ids_in_mnz), i, \"with ids: \", infected_ids_in_mnz)\n",
    "        if len(infected_ids_in_mnz)==0:\n",
    "            continue\n",
    "            \n",
    "#         print(\"adding infected ids to mnz. len mnz2ids[i] before:\", len(mnz2ids[i]))\n",
    "        mnz2ids_inf[i] = np.concatenate([mnz2ids_inf[i], infected_ids_in_mnz])\n",
    "#         print(\"after:\",len(mnz2ids[i]), mnz2ids[i].shape) \n",
    "#         print(\"updating id2mnz\")\n",
    "        for inf_id in infected_ids_in_mnz:\n",
    "            id2mnz_inf[inf_id] = id2mnz_inf.get(inf_id, [])\n",
    "            id2mnz_inf[inf_id].append(i)\n",
    "#             print(\"id2mnz[inf_id]:\",id2mnz[inf_id])\n",
    "        \n",
    "#         print( infected_ids_in_mnz[0])\n",
    "#         if 534833 in infected_ids_in_mnz:\n",
    "#             print(\"534833 found\", infected_ids_in_mnz[0])\n",
    "#         print(\"infected_ids_in_mnz\",infected_ids_in_mnz)\n",
    "        infected_of_interest.append(infected_ids_in_mnz)\n",
    "#         c+=1\n",
    "#         if c>10:\n",
    "#             break\n",
    "\n",
    "\n",
    "\n",
    "    infected_of_interest = np.unique(np.concatenate(infected_of_interest))\n",
    "    print(\"infected_of_interest.shape\",infected_of_interest.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    id2idx={}\n",
    "    c=0\n",
    "    for inf_id in infected_of_interest:\n",
    "        id2idx[inf_id] = len(people_df)+c\n",
    "        c+=1\n",
    "        \n",
    "        \n",
    "    people_df = pd.concat([people_df,pd.DataFrame({\"patient\":infected_of_interest, \n",
    "                                                   \"position\":inf_active.iloc[infected_of_interest-max_id-1].geometry})])\n",
    "    print(\"Concatenated infected to people_df. People_df is now of shape:\", people_df.shape)\n",
    "    print(people_df.columns)\n",
    "\n",
    "    return people_df, mnz2ids_inf, id2mnz_inf, infected_of_interest, id2idx\n",
    "\n",
    "\n",
    "# def include_infected_to_contacts_df(sim, \n",
    "#                                     mnz_data, \n",
    "#                                     path_to_infected_file=os.path.join(shp_path,\"POSITIVOS_COVID_19.shp\"), \n",
    "#                                     T=90, \n",
    "#                                     start_id=0):\n",
    "#     contacts_df_list = []\n",
    "#     c=0\n",
    "#     for i, mnz in tqdm(mnz_data.iterrows()):\n",
    "# #         print(\"searching if any infected in mnz %d\" % i)\n",
    "#         infected_ids_in_mnz = infected_ids[inf_active.geometry.centroid.within(mnz.geometry.buffer(100))]\n",
    "# #         print(\"found %d infected in mnz\" % len(infected_ids_in_mnz))\n",
    "# #         print(infected_ids_in_mnz)\n",
    "#         if len(infected_ids_in_mnz)==0:\n",
    "#             continue\n",
    "            \n",
    "#         ids_in_mnz = mnz2ids[i]\n",
    "#         n_ppl_in_mnz = len(ids_in_mnz)\n",
    "# #         print(\"People in this mnz:\", n_ppl_in_mnz)\n",
    "        \n",
    "#         for date in range(90):\n",
    "#             for id_inf in infected_ids_in_mnz:\n",
    "#                 data = {\n",
    "#                     'date': np.repeat(date, n_ppl_in_mnz),\n",
    "#                     'patient1': np.repeat(id_inf, n_ppl_in_mnz),\n",
    "#                     'patient2': ids_in_mnz\n",
    "#                 }\n",
    "\n",
    "#                 contacts_df_list.append(pd.DataFrame(data=data, columns = [\"date\", \"patient1\", \"patient2\"]))\n",
    "                \n",
    "#         c+=1\n",
    "#         if c>100:break\n",
    "#     print(\"Number of contact dataframes (each correspond to the contacts of one infected on one date): %d\" % len(contacts_df_list))\n",
    "#     infected_contacts = pd.concat(contacts_df_list)\n",
    "#     sim[\"contacts\"].append(infected_contacts)\n",
    "    \n",
    "#     return sim, infected_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2797, 41)\n",
      "Index(['no_caso', 'latitud', 'longitud', 'tipo_ident', 'no_identif',\n",
      "       'prim_nombr', 'seg_nombre', 'prim_apell', 'seg_apelli', 'fecha_hosp',\n",
      "       'dir_reside', 'sect_salud', 'nom_barrio', 'nacionalid', 'fecha_ho_1',\n",
      "       'GlobalID', 'CreationDa', 'Creator', 'EditDate', 'Editor', 'F3_OBJECTI',\n",
      "       'F3_ID', 'F3_FECHA', 'F3_CIUDAD', 'F3_ATENCIO', 'F3_EDAD', 'F3_SEXO',\n",
      "       'F3_TIPO', 'F3_PROCEDE', 'F3_GlobalI', 'F3_FECHATX', 'F3_DPTO',\n",
      "       'F3_FECHA_M', 'F3_FECHA_R', 'F3_COD_DIV', 'F3_RANGO_E', 'F3_ESTADO',\n",
      "       'F3_FIS', 'F3_FIS_NOT', 'F3_COD_DPT', 'geometry'],\n",
      "      dtype='object')\n",
      "Loaded 2797 infected rows\n",
      "people_df.shape before infected concat (534786, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/.local/lib/python3.6/site-packages/ipykernel_launcher.py:29: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f430c437eb4879b861b304fbeac515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "infected_of_interest.shape (1805,)\n",
      "Concatenated infected to people_df. People_df is now of shape: (536591, 2)\n",
      "Index(['patient', 'position'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_to_inf = os.path.join(shp_path, \"CASOS_SARSCOV2_1.shp\")\n",
    "# path_to_inf = os.path.join(shp_path, \"POSITIVOS_COVID_19.shp\")\n",
    "\n",
    "large_people_df_inf, mnz2ids_inf, id2mnz_inf, infected_ids, id2idx = \\\n",
    "     include_infected_to_people_df(large_people_df, mnz2ids, id2mnz, \n",
    "                                   path_to_infected_file = path_to_inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534785\n"
     ]
    }
   ],
   "source": [
    "# Index(['no_caso', 'no_caso_in', 'dia', 'semana', 'direccion', 'barrio',\n",
    "#        'comuna', 'municipio', 'departamen', 'nacionalid', 'tipo_doc',\n",
    "#        'fecha_not', 'sexo', 'edad', 'fecha_resu', 'estado_ate', 'lugar_aten',\n",
    "#        'atencion_h', 'fecha_hosp', 'fecha_de_a', 'fecha_recu', 'fecha_fall',\n",
    "#        'tipo_conta', 'pais_viaje', 'fecha_ingr', 'fecha_ini_', 'fecha_cons',\n",
    "#        'lugar_repo', 'pais_incid', 'fecha_2da_', 'resut_2da_', 'fecha_3ra_',\n",
    "#        'result_3ra', 'eps_fosyga', 'no_contact', 'sintomatic', 'asintomati',\n",
    "#        'trabajador', 'rango_etar', 'GlobalID', 'CreationDa', 'Creator',\n",
    "#        'EditDate', 'Editor', 'seexo', 'nuevo_barr', 'geometry'],\n",
    "#       dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run full simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of people including infected: 536591\n",
      "min and max ids: 537582 0\n",
      "duplicates: Empty DataFrame\n",
      "Columns: [patient, position]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"number of people including infected:\",len(large_people_df_inf))\n",
    "print(\"min and max ids:\", large_people_df_inf[\"patient\"].max(), large_people_df_inf[\"patient\"].min())\n",
    "print(\"duplicates:\", large_people_df_inf[large_people_df_inf[\"patient\"].duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating Simulation\n",
      "536591 Empty DataFrame\n",
      "Columns: [patient, position]\n",
      "Index: []\n",
      "Simulation instantiated. Current people in simulation: 536591\n",
      "Current simulation keys: dict_keys(['map', 'location', 'patients', 'dates', 'mnz2ids', 'id2mnz'])\n",
      "Final number of people to simulate: 536591\n",
      "Average daily contacts for full df: 100.98933731650364\n"
     ]
    }
   ],
   "source": [
    "T=90\n",
    "# if load_people_df:\n",
    "# #     print(type(large_people_df[\"position\"].iloc[0]))\n",
    "#     large_people_df[\"position\"] = large_people_df[\"position\"].apply(wkt.loads)\n",
    "\n",
    "sim_full = instantiate_sim(mnz_data, large_people_df_inf, T=T, reindex=False)\n",
    "sim_full[\"mnz2ids\"] = mnz2ids_inf\n",
    "sim_full[\"id2mnz\"] = id2mnz_inf\n",
    "print(\"Simulation instantiated. Current people in simulation: %d\" % len(sim_full[\"patients\"]))\n",
    "print(\"Current simulation keys:\", sim_full.keys())\n",
    "# print(\"Adding infected\")\n",
    "# # sim_full, infected_ids = include_infected(sim_full, T=T, start_id=len(large_people_df))\n",
    "# print(\"Included %d infected\" % len(infected_ids))\n",
    "print(\"Final number of people to simulate: %d\" % len(sim_full[\"patients\"]))\n",
    "sim_full[\"N_c\"] = contacts.calculate_Nc_for_mnz_approximation(sim_full)/2\n",
    "print(\"Average daily contacts for full df: {}\".format(sim_full[\"N_c\"]))\n",
    "# np.savetxt('sim_states_full.csv', sim_results[\"states\"], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating states...\n",
      "t = 0; 1805 infectious; 0 exposed; 534786 susceptible; 0 dead\n",
      "t = 9; 5945 infectious; 6471 exposed; 520850 susceptible; 2 dead\n",
      "t = 18; 9157 infectious; 6812 exposed; 508277 susceptible; 38 dead\n",
      "t = 27; 9784 infectious; 6249 exposed; 496924 susceptible; 112 dead\n",
      "t = 36; 9365 infectious; 6078 exposed; 486032 susceptible; 207 dead\n",
      "t = 45; 8799 infectious; 5573 exposed; 476081 susceptible; 330 dead\n",
      "t = 54; 8237 infectious; 5182 exposed; 466840 susceptible; 453 dead\n",
      "t = 63; 7630 infectious; 4620 exposed; 458502 susceptible; 569 dead\n",
      "t = 72; 7119 infectious; 4403 exposed; 450551 susceptible; 701 dead\n",
      "t = 81; 6476 infectious; 4183 exposed; 443080 susceptible; 812 dead\n",
      "Calculated states in 11252.29 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Run sim\n",
    "def run_sim(sim, N_infected=15, infected=None):\n",
    "    sim[\"states\"], sim[\"tests\"] = state.simulate_states(sim, N_infected=N_infected, infected=infected)\n",
    "    sim[\"hospital\"] = state.get_first_occurrence(sim[\"states\"], 6)\n",
    "    sim[\"deaths\"] = state.get_first_occurrence(sim[\"states\"], 8)\n",
    "    return sim\n",
    "\n",
    "sim_results = run_sim(sim_full, N_infected=len(infected_ids), infected = infected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating states...\n",
    "# t = 0; 414 infectious; 256131 exposed; 534786 susceptible; 0 dead\n",
    "# t = 9; 1488 infectious; 174936 exposed; 531388 susceptible; 0 dead\n",
    "# t = 18; 2042 infectious; 152402 exposed; 528796 susceptible; 7 dead\n",
    "# t = 27; 1951 infectious; 134483 exposed; 526536 susceptible; 29 dead\n",
    "# t = 36; 1854 infectious; 121621 exposed; 524514 susceptible; 52 dead\n",
    "# t = 45; 1674 infectious; 110857 exposed; 522720 susceptible; 85 dead\n",
    "# t = 54; 1483 infectious; 100745 exposed; 521159 susceptible; 108 dead\n",
    "# t = 63; 1266 infectious; 92763 exposed; 519757 susceptible; 132 dead\n",
    "# t = 72; 1158 infectious; 84446 exposed; 518489 susceptible; 148 dead\n",
    "# t = 81; 1095 infectious; 79720 exposed; 517247 susceptible; 165 dead\n",
    "# Calculated states in 6362.80 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_results=True\n",
    "if save_results:\n",
    "    with open(\"sim_results_new_cases.pkl\", \"wb\") as f:\n",
    "        pickle.dump( sim_results, f )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute aggreg and accum values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2cd8981fd342088eff29926b03856e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=90.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_agreg_accum(sim_results, mzn2ids, id2idx):\n",
    "    states = np.arange(NUM_STATES)\n",
    "    agreg_per_mnz_date_state = {}\n",
    "    accum_per_mnz_date_state = {}\n",
    "    c=0\n",
    "    for date in tqdm(range(sim_results[\"states\"].shape[1])):\n",
    "        processed={i:False for i in sim_results[\"patients\"][\"patient\"]}\n",
    "        agreg_per_mnz_date_state[str(date)] = {}\n",
    "        accum_per_mnz_date_state[str(date)] = {}\n",
    "        for m, ids in mzn2ids.items():\n",
    "            idx_in_mnz = np.zeros_like(ids)\n",
    "            infected_in_this_mnz=0\n",
    "            for j, id_ in enumerate(ids):\n",
    "                if processed[id_]:\n",
    "                    continue\n",
    "                else: \n",
    "                    processed[id_] = True\n",
    "                if id_ in id2idx:\n",
    "                    infected_in_this_mnz+=1\n",
    "                    idx_in_mnz[j] = id2idx[id_]\n",
    "                else:\n",
    "                    idx_in_mnz[j] = id_\n",
    "\n",
    "            agreg_per_mnz_date_state[str(date)][str(m)] = {}\n",
    "            accum_per_mnz_date_state[str(date)][str(m)] = {}\n",
    "            for s in states:\n",
    "                counts = np.sum(sim_results[\"states\"][idx_in_mnz, date]==s)\n",
    "                agreg_per_mnz_date_state[str(date)][str(m)][str(s)] = int(counts)\n",
    "                \n",
    "                if date == 0:\n",
    "                    accum_per_mnz_date_state[str(date)][str(m)][str(s)] = int(counts)\n",
    "                else:\n",
    "                    new_counts = int(np.sum((np.array(sim_results[\"states\"][idx_in_mnz, date-1]==s, dtype=int)-np.array(sim_results[\"states\"][idx_in_mnz, date]==s, dtype=int)) <0))\n",
    "                    accum_per_mnz_date_state[str(date)][str(m)][str(s)] = accum_per_mnz_date_state[str(date-1)][str(m)][str(s)] + new_counts\n",
    "    return agreg_per_mnz_date_state, accum_per_mnz_date_state\n",
    "\n",
    "agreg_per_mnz_date_state, accum_per_mnz_date_state = compute_agreg_accum(sim_results, mnz2ids_inf, id2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data with right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:fiona._env:mnz_data.geojson: No such file or directory\n",
      "WARNING:fiona._env:driver GeoJSON does not support creation option ENCODING\n",
      "/home/camilo/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30befa030af448909bb48c5eccfa08c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5964.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def save_as_geojson(agreg_per_mnz_date_state, accum_per_mnz_date_state, outfile=\"mnz_data_with_states.geojson\"):\n",
    "    import pygeoj\n",
    "\n",
    "    mnz_data_2 = gpd.read_file(os.path.join(shp_path,\"Censo_personas_manzanas_2018.shp\"))\n",
    "    mnz_data_2 = mnz_data_2.to_crs({\"init\": \"EPSG:4326\"})\n",
    "\n",
    "    mnz_data_2.to_file(\"mnz_data.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "    mnz_geojson = pygeoj.load(filepath=\"mnz_data.geojson\")\n",
    "    for i in tqdm(range(len(mnz_geojson))):\n",
    "        feat = mnz_geojson[i]\n",
    "        feat.properties[\"daily\"]={str(d): md[str(i)] for d, md in agreg_per_mnz_date_state.items()}\n",
    "        feat.properties[\"acum\"]={str(d): md[str(i)] for d, md in accum_per_mnz_date_state.items()}\n",
    "\n",
    "    mnz_geojson.save(outfile)\n",
    "    \n",
    "    \n",
    "def save_as_js(geojson_to_load):\n",
    "    \n",
    "    text = json.load(open(geojson_to_load, \"r+\"))\n",
    "    text = \"data=%s\" % text\n",
    "    f = open(geojson_to_load.split(\".\")[0]+\".js\", \"w+\")\n",
    "    f.write(text)\n",
    "    f.close()\n",
    "    \n",
    "save_as_geojson(agreg_per_mnz_date_state, accum_per_mnz_date_state, outfile=\"datos_manzana.geojson\")\n",
    "save_as_js(\"datos_manzana.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ranges\n",
    "\n",
    "def get_ranges(agreg_per_mnz_date_state):\n",
    "    ranges={str(i):{\"min\":1e7, \"max\":-1e7} for i in range(9)}\n",
    "\n",
    "    for mnz_id, mnz_state in agreg_per_mnz_date_state.items():\n",
    "        for date, states_dict in mnz_state.items():\n",
    "            for s, c in states_dict.items():\n",
    "                if c > ranges[s][\"max\"]:\n",
    "                    ranges[s][\"max\"] = c\n",
    "                elif c < ranges[s][\"min\"]:\n",
    "                    ranges[s][\"min\"] = c\n",
    "    \n",
    "    return ranges\n",
    "\n",
    "ranges={}\n",
    "ranges[\"daily\"] = get_ranges(agreg_per_mnz_date_state)\n",
    "ranges[\"acum\"] = get_ranges(accum_per_mnz_date_state)\n",
    "\n",
    "json.dump(ranges, open(\"rangos.json\", \"w+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute global metrics (over the whole city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute state sum per day for all mnz\n",
    "\n",
    "def get_global_metrics(agreg_per_mnz_date_state, accum_per_mnz_date_state):\n",
    "    agreg_full = {str(d):{str(s):0 for s in range(9)} for d in range(T)}\n",
    "    for d, mnz_dict in agreg_per_mnz_date_state.items():\n",
    "        for m, sd in mnz_dict.items():\n",
    "            for s, c in sd.items():\n",
    "                agreg_full[d][s] += c\n",
    "    accum_full = {str(d):{str(s):0 for s in range(9)} for d in range(T)}\n",
    "    for d, mnz_dict in accum_per_mnz_date_state.items():\n",
    "        for m, sd in mnz_dict.items():\n",
    "            for s, c in sd.items():\n",
    "                accum_full[d][s] += c\n",
    "    \n",
    "    return agreg_full, accum_full\n",
    "\n",
    "\n",
    "agreg_full, accum_full = get_global_metrics(agreg_per_mnz_date_state, accum_per_mnz_date_state)\n",
    "full={}\n",
    "full[\"daily\"] = agreg_full\n",
    "full[\"acum\"] = accum_full\n",
    "\n",
    "json.dump(full, open(\"datos_ciudad.json\", \"w+\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accum_por_mnz = {}\n",
    "# for d, mnz_dict in states_accum.items():\n",
    "#     accum_por_mnz[str(d)] = {}\n",
    "#     for m, sd in mnz_dict.items():\n",
    "#         accum_por_mnz[str(d)][str(m)] = {}\n",
    "#         for s, c in sd.items():\n",
    "#             accum_por_mnz[str(d)][str(m)][str(s)] = c + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: SIMULATE WITH ESTIMATED ASYMPTOMATICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/.local/lib/python3.6/site-packages/ipykernel_launcher.py:32: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b469eff17d434316ad213f0d38094bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all_asymp.shape (5329,)\n",
      "len asymp_pos 5329\n",
      "Concatenated asymp to people_df. People_df is now of shape: (541920, 2)\n",
      "Index(['patient', 'position'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def add_estimated_undetected_from_death_rate():\n",
    "    infected_shp = gpd.read_file(os.path.join(shp_path,\"POSITIVOS_COVID_19.shp\"))\n",
    "    infected_shp[infected_shp[\"estado_ate\"]==3][\"fecha_fall\"]\n",
    "    dead = infected_shp[infected_shp[\"estado_ate\"]==3]\n",
    "    print(\"dead in data:\",len(dead))\n",
    "    all_dead = 0\n",
    "\n",
    "    for i, mnz in tqdm(mnz_data.iterrows()):\n",
    "    #     print(\"\\nsearching if any dead in mnz %d\" % i)\n",
    "        dead_in_mnz = sum(dead.geometry.centroid.within(mnz.geometry))\n",
    "        if dead_in_mnz == 0:\n",
    "            continue\n",
    "    #     print(\"found %d dead in mnz\" % dead_in_mnz, i)\n",
    "        all_dead+=dead_in_mnz\n",
    "\n",
    "def add_estimated_asymp_to_people_df(people_df, \n",
    "                                 mnz2ids, \n",
    "                                 id2mnz,\n",
    "                                 id2idx,\n",
    "                                 T=90):\n",
    "\n",
    "    mnz2ids_a = deepcopy(mnz2ids)\n",
    "    id2mnz_a = deepcopy(id2mnz)\n",
    "    id2idx_a = deepcopy(id2idx)\n",
    "    \n",
    "    ASYMP_RATE = 0.16\n",
    "    \n",
    "    max_id = people_df.patient.max()\n",
    "    all_asymp = []\n",
    "    asymp_pos = []\n",
    "    \n",
    "    for i, mnz in tqdm(mnz_data.iterrows()):\n",
    "        \n",
    "        ppl_in_mnz = mnz[\"SEXO_TOTAL\"]\n",
    "        inf_in_mnz = np.sum( mnz2ids[i]>534786 ) \n",
    "        if not ppl_in_mnz or not inf_in_mnz:\n",
    "            continue\n",
    "        \n",
    "#         print(\"mnz %d has infecteds:\"%i, mnz2ids[i])\n",
    "        # calculate_estimated_asymp\n",
    "        estim_asymp = ASYMP_RATE*inf_in_mnz\n",
    "        if estim_asymp!=0:\n",
    "            if estim_asymp<1:\n",
    "                estim_asymp = 1\n",
    "            else:\n",
    "                estim_asymp=np.round(estim_asymp)\n",
    "            \n",
    "#         print(estim_asymp)\n",
    "    \n",
    "        asymp_ids = np.arange(estim_asymp, dtype=int)+max_id+1 \n",
    "        max_id = asymp_ids[-1]\n",
    "\n",
    "        mnz2ids_a[i] = np.concatenate([mnz2ids_a[i], asymp_ids])\n",
    "    \n",
    "        for asymp_id in asymp_ids:\n",
    "            id2mnz_a[asymp_id] = id2mnz.get(asymp_id, [])\n",
    "            id2mnz_a[asymp_id].append(i)\n",
    "#             print(\"id2mnz[asymp_id]:\",id2mnz[asymp_id])\n",
    "         \n",
    "        all_asymp.append(asymp_ids)\n",
    "        asymp_pos.extend([mnz.geometry.centroid]*int(estim_asymp))\n",
    "        \n",
    "\n",
    "    \n",
    "    all_asymp = np.concatenate(all_asymp)\n",
    "\n",
    "    \n",
    "    print(\"all_asymp.shape\",all_asymp.shape)\n",
    "    print(\"len asymp_pos\",len(asymp_pos))\n",
    "    \n",
    "    \n",
    "    c=0\n",
    "    for a_id in all_asymp:\n",
    "        id2idx_a[a_id] = len(people_df)+c\n",
    "        c+=1\n",
    "        \n",
    "    \n",
    "        \n",
    "    people_df = pd.concat([people_df, pd.DataFrame({\"patient\":all_asymp, \n",
    "                                                   \"position\":asymp_pos})])\n",
    "    print(\"Concatenated asymp to people_df. People_df is now of shape:\", people_df.shape)\n",
    "    print(people_df.columns)\n",
    "    \n",
    "    return people_df, mnz2ids_a, id2mnz_a, all_asymp, id2idx_a\n",
    "\n",
    "large_people_df_a, mnz2ids_a, id2mnz_a, asymp_ids, id2idx_a  = \\\n",
    "    add_estimated_asymp_to_people_df(large_people_df_inf, \n",
    "                                 mnz2ids_inf, \n",
    "                                 id2mnz_inf,\n",
    "                                 id2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating Simulation\n",
      "541920 Empty DataFrame\n",
      "Columns: [patient, position]\n",
      "Index: []\n",
      "Simulation instantiated. Current people in simulation: 541920\n",
      "Current simulation keys: dict_keys(['map', 'location', 'patients', 'dates', 'mnz2ids', 'id2mnz'])\n",
      "Final number of people to simulate: 541920\n",
      "Average daily contacts for full df: 101.19742766459994\n",
      "Calculating states...\n",
      "t = 0; 7134 infectious; 0 exposed; 534786 susceptible; 0 dead\n",
      "t = 9; 7460 infectious; 6669 exposed; 520534 susceptible; 9 dead\n",
      "t = 18; 9870 infectious; 7038 exposed; 507543 susceptible; 48 dead\n",
      "t = 27; 10167 infectious; 6618 exposed; 495549 susceptible; 124 dead\n",
      "t = 36; 9824 infectious; 6078 exposed; 484509 susceptible; 255 dead\n",
      "t = 45; 9317 infectious; 5520 exposed; 474241 susceptible; 396 dead\n",
      "t = 54; 8624 infectious; 5363 exposed; 464330 susceptible; 523 dead\n",
      "t = 63; 7995 infectious; 4953 exposed; 455383 susceptible; 636 dead\n",
      "t = 72; 7423 infectious; 4595 exposed; 447090 susceptible; 745 dead\n",
      "t = 81; 6993 infectious; 4313 exposed; 439233 susceptible; 872 dead\n",
      "Calculated states in 11577.82 seconds.\n"
     ]
    }
   ],
   "source": [
    "T=90\n",
    "sim_full_a = instantiate_sim(mnz_data, large_people_df_a, T=T, reindex=False)\n",
    "sim_full_a[\"mnz2ids\"] = mnz2ids_a\n",
    "sim_full_a[\"id2mnz\"] = id2mnz_a\n",
    "print(\"Simulation instantiated. Current people in simulation: %d\" % len(sim_full_a[\"patients\"]))\n",
    "print(\"Current simulation keys:\", sim_full_a.keys())\n",
    "print(\"Final number of people to simulate: %d\" % len(sim_full_a[\"patients\"]))\n",
    "sim_full_a[\"N_c\"] = contacts.calculate_Nc_for_mnz_approximation(sim_full_a)/2\n",
    "print(\"Average daily contacts for full df: {}\".format(sim_full_a[\"N_c\"]))\n",
    "\n",
    "def run_sim(sim, N_infected=15, infected=None, asymp=None):\n",
    "    sim[\"states\"], sim[\"tests\"] = state.simulate_states(sim, \n",
    "                                                        N_infected=N_infected, \n",
    "                                                        infected=infected,\n",
    "                                                        asymp=asymp)\n",
    "    sim[\"hospital\"] = state.get_first_occurrence(sim[\"states\"], 6)\n",
    "    sim[\"deaths\"] = state.get_first_occurrence(sim[\"states\"], 8)\n",
    "    return sim\n",
    "\n",
    "sim_results_a = run_sim(sim_full_a, N_infected=len(infected_ids), infected = infected_ids, asymp=asymp_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get accum and aggreg, save, get ranges, compute global values for asymp sim results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a47a8999fc146bba4bf5ea46a083b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=90.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:fiona._env:mnz_data.geojson: No such file or directory\n",
      "WARNING:fiona._env:driver GeoJSON does not support creation option ENCODING\n",
      "/home/camilo/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b581565b11f24b24ac7a941cc918363d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5964.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## GET ACCUM AND AGGREG VALUES\n",
    "agreg_per_mnz_date_state_a, accum_per_mnz_date_state_a = compute_agreg_accum(sim_results_a, mnz2ids_a, id2idx_a)\n",
    "\n",
    "## SAVE WITH RIGHT FORMAT\n",
    "save_as_geojson(agreg_per_mnz_date_state_a, accum_per_mnz_date_state_a, outfile=\"datos_manzana_asymp.geojson\")\n",
    "save_as_js(\"datos_manzana_asymp.geojson\")\n",
    "\n",
    "## GET RANGES\n",
    "ranges_a={}\n",
    "ranges_a[\"daily\"] = get_ranges(agreg_per_mnz_date_state_a)\n",
    "ranges_a[\"acum\"] = get_ranges(accum_per_mnz_date_state_a)\n",
    "json.dump(ranges_a, open(\"rangos_asymp.json\", \"w+\"))\n",
    "\n",
    "## COMPUTE GLOBAL VALUES\n",
    "agreg_full_a, accum_full_a = get_global_metrics(agreg_per_mnz_date_state_a, accum_per_mnz_date_state_a)\n",
    "full_a = {\"daily\":agreg_full_a, \"acum\": accum_full_a}\n",
    "json.dump(full_a, open(\"datos_ciudad_asymp.json\", \"w+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative: compute full contacts with heavy parallelism\n",
    "Unused for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_contacts(polygon, points, date):\n",
    "    \n",
    "#     _people = points[points.geometry.centroid.within(polygon.geometry.buffer(100))]\n",
    "# #     print(len(_people))\n",
    "#     data = {\n",
    "#         'date': np.repeat(date, len(_people)),\n",
    "#         'patient1': np.repeat(polygon['patient'], len(_people)),\n",
    "#         'patient2': list(_people['patient'])\n",
    "#     }\n",
    "    \n",
    "#     exposure_df = pd.DataFrame(data=data, columns = [\"date\", \"patient1\", \"patient2\"])\n",
    "#     return exposure_df\n",
    "\n",
    "# def calculate_daily_contacts(people_proj, sim, load_from_csv=False):\n",
    "    \n",
    "#     if load_from_csv:\n",
    "#         return pd.read_csv(\"improved_daily_contacts.csv\")\n",
    "    \n",
    "#     start = timer()\n",
    "\n",
    "#     # calculate daily contacts for day 1 as they will be repeated for the other days\n",
    "#     date = sim[\"dates\"][\"date\"][0]\n",
    "#     daily_contacts = people_proj.swifter.apply(calculate_contacts, axis=1, args=[people_proj, date])\n",
    "\n",
    "#     original_daily_contacts = pd.concat(list(daily_contacts), sort=False)\n",
    "#     original_daily_contacts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#     # calculate the table for all the dates\n",
    "#     improved_daily_contacts = original_daily_contacts.copy()\n",
    "#     for date in sim[\"dates\"][\"date\"]:\n",
    "#         if len(original_daily_contacts[original_daily_contacts['date'] == date]) < 1:\n",
    "#             new_df = original_daily_contacts.copy()\n",
    "#             new_df['date'] = date\n",
    "#             improved_daily_contacts = improved_daily_contacts.append(new_df)\n",
    "\n",
    "#     improved_daily_contacts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#     end = timer()\n",
    "#     print(\"Compute time:\",end-start)\n",
    "    \n",
    "#     return improved_daily_contacts\n",
    "\n",
    "# full_daily_contacts = calculate_daily_contacts(large_people_df, sim_full, load_from_csv=False)\n",
    "# sim_full[\"contacts\"] = full_daily_contacts\n",
    "# sim_full[\"N_c\"] = contacts.calculate_Nc(sim_full)\n",
    "# print(\"Average daily contacts: {}\".format(sim_full[\"N_c\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
